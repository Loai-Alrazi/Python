import json
import requests
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from datetime import datetime

class TelegramAIBackend:
    def __init__(self):
        # 1. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ
        self.all_messages = []
        self.users_stats = {}
        self.my_accounts = ["Ù„Ø¤ÙŠ Ø§Ù„Ø±Ø§Ø²ÙŠ", "Ø§Ù„ÙØ­Ù€à¹›Ù€Ù€Ù€Ù€Ù€Ø¢Ù…ÙŒ", "Ù‚Ù†Ø§Ø© Ø§Ù„ÙØ­Ù€à¹›Ù€Ù€Ù€Ù€Ù€Ø¢Ù…ÙŒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"]
        
        # 2. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ (Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ø­Ù„ÙŠØ§Ù‹)
        print("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø­Ù„ÙŠ...")
        # self.semantic_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        # Ø£Ø¶Ù local_files_only=True Ù„ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª
        self.semantic_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu')
        self.index = None
        self.rich_texts = []

    def load_data(self, file_paths):
        """ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ù† Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª JSON"""
        self.all_messages = []
        for path in file_paths:
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Ø¯Ù…Ø¬ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ù† ÙƒÙ„ Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
                    self.all_messages.extend(data.get('messages', []))
                print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬: {path}")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {path}: {e}")
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø²Ù…Ù†ÙŠØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
        self.all_messages.sort(key=lambda x: x.get('date', ''))
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬: {len(self.all_messages)}")

    def build_semantic_index(self):
        """Ø¨Ù†Ø§Ø¡ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…Ø¹Ù†Ù‰"""
        print("ğŸ§  Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ... (Ø¨Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±)")
        self.rich_texts = [self._get_text(m) for m in self.all_messages if len(self._get_text(m)) > 20]
        embeddings = self.semantic_model.encode(self.rich_texts, show_progress_bar=True)
        
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(np.array(embeddings).astype('float32'))
        print("âœ… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø¹Ù…Ù„.")

    def _get_text(self, msg):
        text = msg.get('text', '')
        if isinstance(text, list):
            return "".join([t if isinstance(t, str) else t.get('text', '') for t in text])
        return str(text)

    def ask_ai(self, question):
        """Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„ÙƒØ¨Ø±Ù‰: Ø§Ø¨Ø­Ø« ÙÙŠ FAISS Ø«Ù… Ø§Ø³Ø£Ù„ Llama"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
        query_vec = self.semantic_model.encode([question]).astype('float32')
        _, indices = self.index.search(query_vec, k=5)
        context = "\n".join([self.rich_texts[i] for i in indices[0]])
        
        # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù€ Ollama
        prompt = f"Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª:\n{context}\n\nØ³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {question}\nØ£Ø¬Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙÙ‚Ø·."
        
        try:
            r = requests.post('http://localhost:11434/api/generate', 
                            json={"model": "llama3.2:1b", "prompt": prompt, "stream": False})
            return r.json().get('response', "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø¯.")
        except:
            return "âŒ Ø®Ø·Ø£: ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ollama."

                    