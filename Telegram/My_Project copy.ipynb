{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8560afa3",
   "metadata": {},
   "source": [
    "# 1. Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø© ÙˆØ§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Initialization & Engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "819a3f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class TelegramProAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.messages_dict = {}  # Ù„Ù„ÙÙ‡Ø±Ø³Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø© Ø¨Ù€ ID Ø§Ù„Ø±Ø³Ø§Ù„Ø©\n",
    "        self.users_stats = {}    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ù…Ø³ØªØ®Ø¯Ù…\n",
    "        self.interactions = {}   # Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª (Ù…Ù† Ø±Ø¯ Ø¹Ù„Ù‰ Ù…Ù†)\n",
    "        self.all_messages_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990156c",
   "metadata": {},
   "source": [
    "# 2. Ø¹Ù…Ù„ÙŠØ© ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Loading & Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c53bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load_and_clean(self, file_paths):\n",
    "            for file_path in file_paths:\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        data = json.load(f)\n",
    "                        for msg in data.get('messages', []):\n",
    "                            msg_id = msg.get('id')\n",
    "                            self.messages_dict[msg_id] = msg\n",
    "                            self.all_messages_list.append(msg)\n",
    "                    print(f\"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆØªÙ†Ø¸ÙŠÙ: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {file_path}: {e}\")\n",
    "\n",
    "    def process_data(self):\n",
    "    # ØªØ±ØªÙŠØ¨ Ø²Ù…Ù†ÙŠ Ù„Ø¶Ù…Ø§Ù† ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«\n",
    "        self.all_messages_list.sort(key=lambda x: x.get('date', ''))\n",
    "\n",
    "        for msg in self.all_messages_list:\n",
    "            sender_id = msg.get('from_id')\n",
    "            sender_name = msg.get('from', 'Unknown')\n",
    "            \n",
    "            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ: ØªÙ„Ø¬Ø±Ø§Ù… Ù‚Ø¯ ÙŠØ±Ø³Ù„ Ø§Ù„Ù†Øµ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚\n",
    "            text_data = msg.get('text')\n",
    "            if isinstance(text_data, list):\n",
    "                text = \"\".join([part if isinstance(part, str) else part.get('text', '') for part in text_data])\n",
    "            else:\n",
    "                text = text_data\n",
    "\n",
    "            reply_to = msg.get('reply_to_message_id')\n",
    "\n",
    "            if sender_id and isinstance(text, str) and text.strip():\n",
    "                # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…\n",
    "                if sender_id not in self.users_stats:\n",
    "                    self.users_stats[sender_id] = {\n",
    "                        'name': sender_name, 'msg_count': 0, \n",
    "                        'words_count': 0, 'replies_sent': 0, 'received_replies': 0\n",
    "                    }\n",
    "                \n",
    "                stats = self.users_stats[sender_id]\n",
    "                stats['msg_count'] += 1\n",
    "                stats['words_count'] += len(text.split())\n",
    "\n",
    "                # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯ÙˆØ¯\n",
    "                if reply_to:\n",
    "                    stats['replies_sent'] += 1\n",
    "                    original_msg = self.messages_dict.get(reply_to)\n",
    "                    if original_msg:\n",
    "                        target_id = original_msg.get('from_id')\n",
    "                        if target_id and target_id in self.users_stats:\n",
    "                            self.users_stats[target_id]['received_replies'] += 1\n",
    "                            pair = (sender_id, target_id)\n",
    "                            self.interactions[pair] = self.interactions.get(pair, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52385b2e",
   "metadata": {},
   "source": [
    "# 3. Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³ÙŠØ§Ù‚ (Analytics & Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f05dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_pro(self, text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text) # Ø­Ø°Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø·\n",
    "        text = re.sub(r'[^\\w\\s]', '', text) # Ø­Ø°Ù Ø§Ù„Ø±Ù…ÙˆØ²\n",
    "        text = re.sub(r'(Ù‡Ù€|Ù‡){3,}', 'Ù‡Ù‡Ù‡', text) # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¶Ø­Ùƒ\n",
    "        \n",
    "        stop_words = {\"Ù…Ù†\", \"Ø¹Ù„Ù‰\", \"ÙÙŠ\", \"Ø§Ù„Ù‰\", \"Ø°Ø§\", \"Ø§Ù„\", \"Ø§Ù†\", \"ÙŠØ§\", \"Ùˆ\", \"Ø§Ùˆ\"}\n",
    "        words = text.split()\n",
    "        return \" \".join([w for w in words if w not in stop_words])\n",
    "\n",
    "def get_context_around_message(self, message_id, window_size=5):\n",
    "    for i, msg in enumerate(self.all_messages_list):\n",
    "        if msg.get('id') == message_id:\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(len(self.all_messages_list), i + window_size + 1)\n",
    "            context = self.all_messages_list[start:end]\n",
    "            \n",
    "            formatted = \"\"\n",
    "            for c in context:\n",
    "                name = c.get('from', 'Unknown')\n",
    "                txt = c.get('text', '')\n",
    "                formatted += f\"{name}: {txt}\\n\"\n",
    "            return formatted\n",
    "    return \"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d76ab",
   "metadata": {},
   "source": [
    "#  4. Ø¹Ù…Ù„ÙŠØ© Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Reporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be6016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_report(self):\n",
    "        print(f\"\\n{'Ø§Ù„Ø§Ø³Ù…':<35} | {'Ø§Ù„Ø±Ø³Ø§Ø¦Ù„':<10} | {'Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù…Ø±Ø³Ù„Ø©':<15} | {'Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª':<15}\")\n",
    "        print(\"-\" * 85)\n",
    "        \n",
    "        for uid, s in self.users_stats.items():\n",
    "            safe_name = str(s['name']) if s['name'] is not None else \"Ø­Ø³Ø§Ø¨ Ù…Ø­Ø°ÙˆÙ\"\n",
    "            if len(safe_name) > 32: safe_name = safe_name[:29] + \"...\"\n",
    "            print(f\"{safe_name:<35} | {s['msg_count']:<10} | {s['replies_sent']:<15} | {s['received_replies']:<15}\")\n",
    "\n",
    "        if self.interactions:\n",
    "            best_pair = max(self.interactions, key=self.interactions.get)\n",
    "            p1 = self.users_stats[best_pair[0]]['name'] or \"Unknown\"\n",
    "            p2 = self.users_stats[best_pair[1]]['name'] or \"Unknown\"\n",
    "            print(f\"\\nğŸ’¡ Ø£ÙƒØ«Ø± Ø«Ù†Ø§Ø¦ÙŠ ØªÙØ§Ø¹Ù„Ø§Ù‹: {p1} <-> {p2} ({self.interactions[best_pair]} Ø±Ø¯)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ad46a",
   "metadata": {},
   "source": [
    "# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ÙØªØ§Ø­ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ba439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# 1. Ø¶Ø¹ Ù…ÙØªØ§Ø­Ùƒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù‡Ù†Ø§\n",
    "NEW_API_KEY = \"AIzaSyDNDNSmnFOUuB4aHROHL3awkWNuMxJ58CA\"\n",
    "genai.configure(api_key=NEW_API_KEY)\n",
    "\n",
    "print(\"ğŸ” Ø¨Ø¯Ø£Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ´Ø®ÙŠØµ...\")\n",
    "\n",
    "try:\n",
    "    # Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª\n",
    "    print(\"1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù…ÙØªØ§Ø­Ùƒ...\")\n",
    "    models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
    "    \n",
    "    if not models:\n",
    "        print(\"âŒ ØªØ­Ø°ÙŠØ±: Ø§Ù„Ù…ÙØªØ§Ø­ ÙŠØ¹Ù…Ù„ ÙˆÙ„ÙƒÙ† Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…ÙØ¹Ù„Ø© Ø¹Ù„ÙŠÙ‡!\")\n",
    "    else:\n",
    "        print(f\"âœ… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© Ù„Ùƒ Ù‡ÙŠ: {models}\")\n",
    "        \n",
    "        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø³ÙŠØ· Ø¬Ø¯Ø§Ù‹ (Gemini Pro Ø§Ù„Ù‚Ø¯ÙŠÙ…)\n",
    "        selected = models[0] # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ ÙˆØ§Ø­Ø¯ Ù…ØªØ§Ø­ ÙØ¹Ù„ÙŠØ§Ù‹\n",
    "        print(f\"2. ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙˆØ¯ÙŠÙ„: {selected}\")\n",
    "        test_model = genai.GenerativeModel(selected)\n",
    "        response = test_model.generate_content(\"Say 'Hello' if you can hear me\")\n",
    "        print(f\"ğŸ“¡ Ø±Ø¯ Ø§Ù„Ø¨ÙˆØª: {response.text}\")\n",
    "        print(\"--- ğŸ‰ Ù…Ø¨Ø±ÙˆÙƒ! Ø§Ù„Ù…ÙØªØ§Ø­ ÙˆØ§Ù„Ø§ØªØµØ§Ù„ ÙŠØ¹Ù…Ù„Ø§Ù† Ø¨Ù†Ø¬Ø§Ø­ ØªØ§Ù… ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ÙØªØ§Ø­ Ø£Ùˆ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {e}\")\n",
    "    if \"API_KEY_INVALID\" in str(e):\n",
    "        print(\"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø°ÙŠ Ø£Ø¯Ø®Ù„ØªÙ‡ ØºÙŠØ± ØµØ­ÙŠØ­ Ø£Ùˆ Ù„Ù… ÙŠÙØ¹Ù„ Ø¨Ø¹Ø¯.\")\n",
    "    elif \"403\" in str(e):\n",
    "        print(\"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø­Ø³Ø§Ø¨Ùƒ Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ù„ØªÙØ¹ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ Ø£Ùˆ Ù‡Ù†Ø§Ùƒ Ù‚ÙŠÙˆØ¯ Ø¬ØºØ±Ø§ÙÙŠØ©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbe82d6",
   "metadata": {},
   "source": [
    "# Ø£Ù„Ù Ù…Ø¨Ø±ÙˆÙƒ! Ù„Ù‚Ø¯ Ù†Ø¬Ø­Ù†Ø§ Ø£Ø®ÙŠØ±Ø§Ù‹. Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù…ØªÙŠØ§Ø²ØŒ ÙˆØ§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø£ØµØ¨Ø­ ÙˆØ§Ø¶Ø­Ø§Ù‹ Ø§Ù„Ø¢Ù†: Ø­Ø³Ø§Ø¨Ùƒ Ù„Ø¯ÙŠÙ‡ ÙˆØµÙˆÙ„ Ù„Ù†Ù…Ø§Ø°Ø¬ Ø­Ø¯ÙŠØ«Ø© Ø¬Ø¯Ø§Ù‹ (Ù…Ø«Ù„ Gemini 2.5 Flash) ÙˆÙ‡ÙŠ Ø£Ø­Ø¯Ø« Ø¨ÙƒØ«ÙŠØ± Ù…Ù…Ø§ ÙƒÙ†Ø§ Ù†ØªÙˆÙ‚Ø¹Ù‡!\n",
    "<!--\n",
    "Ø¨Ù…Ø§ Ø£Ù†Ùƒ ØªÙ…ØªÙ„Ùƒ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù…ÙˆØ¯ÙŠÙ„ gemini-2.5-flashØŒ ÙÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ùƒ ØªÙ…ØªÙ„Ùƒ \"Ø®Ø§Ø±Ù‚ Ø°ÙƒØ§Ø¡\" Ø­Ù‚ÙŠÙ‚ÙŠØ› ÙÙ‡Ùˆ Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹ ÙˆÙŠÙ…ØªÙ„Ùƒ Ø°Ø§ÙƒØ±Ø© (Context Window) Ø¹Ù…Ù„Ø§Ù‚Ø© ØªØ³ØªØ·ÙŠØ¹ Ø§Ø³ØªÙŠØ¹Ø§Ø¨ ÙƒÙ„ Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© (Ø§Ù„Ù€ 20 Ø£Ù„Ù Ø±Ø³Ø§Ù„Ø©) ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯ Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„ØªÙ‚Ø³ÙŠÙ…Ù‡Ø§!\n",
    "-->><>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯\n",
    "NEW_API_KEY = \"Ø¶Ù€Ø¹_Ù…ÙØªØ§Ø­Ùƒ_Ø§Ù„Ø¬Ø¯ÙŠØ¯_Ù‡Ù†Ø§\"\n",
    "genai.configure(api_key=NEW_API_KEY)\n",
    "\n",
    "# 2. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚ÙˆÙŠ Ø§Ù„Ø°ÙŠ Ø¸Ù‡Ø± ÙÙŠ Ø§Ù„ÙØ­Øµ\n",
    "model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
    "\n",
    "def ask_group_memory(question, engine_instance):\n",
    "    # Ø¨ÙØ¶Ù„ Ù‚ÙˆØ© Gemini 2.5ØŒ Ø³Ù†Ø£Ø®Ø° 10,000 Ø±Ø³Ø§Ù„Ø© Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©!\n",
    "    # Ù‡Ø°Ø§ Ø³ÙŠØ¹Ø·ÙŠ Ø§Ù„Ø¨ÙˆØª Ù‚Ø¯Ø±Ø© Ù…Ø°Ù‡Ù„Ø© Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ\n",
    "    messages_to_send = engine_instance.all_messages_list[:10000]\n",
    "    \n",
    "    context = \"\"\n",
    "    for msg in messages_to_send:\n",
    "        sender = msg.get('from', 'Unknown')\n",
    "        text_data = msg.get('text', '')\n",
    "        text = \"\".join([part if isinstance(part, str) else part.get('text', '') for part in text_data]) if isinstance(text_data, list) else text_data\n",
    "        \n",
    "        if text and str(text).strip():\n",
    "            context += f\"{sender}: {text}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙˆÙ…Ø¤Ø±Ø® Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©. \n",
    "    Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ù…Ø±ÙÙ‚. \n",
    "    ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆØ­Ø§ÙˆÙ„ Ø°ÙƒØ± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø§Ù„Ø°ÙŠÙ† Ø´Ø§Ø±ÙƒÙˆØ§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹.\n",
    "\n",
    "    Ø§Ù„Ø³Ø¤Ø§Ù„: {question}\n",
    "\n",
    "    Ø§Ù„Ø³Ø¬Ù„:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}\"\n",
    "\n",
    "# 3. Ø·Ø±Ø­ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ù†ØªØ¸Ø±\n",
    "question = \"Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„ÙŠÙ‡ÙˆØ¯ ÙˆØ§Ù„Ø§ÙˆÙ„ÙŠØ§Ø¡ ÙÙŠ Ù†Ø¸Ø± Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©ØŸ\"\n",
    "print(f\"ğŸ¤– Ø§Ù„Ø¨ÙˆØª (Gemini 2.5) ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø¢Ù† Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©...\")\n",
    "print(\"-\" * 40)\n",
    "print(ask_group_memory(question, engine))\n",
    "print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
